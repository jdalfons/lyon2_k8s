{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, Ridge, ElasticNet, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Palmer_Archipelago_Penguin_Data_size.csv')\n",
    "datac = data.copy() \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include='object').columns:\n",
    "    print(data[col].value_counts())\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex'] = data['sex'].replace('.', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'duplicated values: {data.duplicated().sum().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all').T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.isna().sum())\n",
    "\n",
    "filtered_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.species.unique())\n",
    "print(filtered_data.island.unique())\n",
    "print(filtered_data.sex.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "The categorical value:\n",
    "\n",
    "- species\t\n",
    "- island\n",
    "- sex\n",
    "\n",
    "The numeric value:\n",
    "\n",
    "- culmen_length_mm\t\n",
    "- culmen_depth_mm\t\n",
    "- flipper_length_mm\t\n",
    "- body_mass_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['species', 'island','sex']\n",
    "numerical_vars = ['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHisto(data, variable, group='species'):\n",
    "    plt.figure()\n",
    "    for species in data[group].unique():\n",
    "        subset = data[data[group] == species]\n",
    "        plt.hist(subset[variable], bins=100, alpha=0.5, label=species)\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Penguin - {}\" .format(variable))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plotBar(data, variable, n=5):\n",
    "\n",
    "    plt.figure()\n",
    "    sns.countplot(data=data, x=variable, order=data[variable].value_counts().index[:n], palette=\"Set2\")\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Penguin - {}\" .format(variable))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def showData(data, variable):\n",
    "    print(data[variable].describe())\n",
    "    \n",
    "    \n",
    "def boxPlotMethod(data, variable, group='species'):\n",
    "    sns.boxplot(x=group, y=variable, data=data, hue=group, palette=\"Set2\", legend=False)\n",
    "    plt.title(f'Boxplot of {variable} by {group}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in categorical_vars:\n",
    "    showData(filtered_data, var)\n",
    "    plotBar(filtered_data, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(filtered_data, hue=\"species\", size=3,diag_kind=\"hist\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in numerical_vars:\n",
    "    boxPlotMethod(filtered_data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = filtered_data[numerical_vars].corr()\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Optionally, you can visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='crest', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "dict_vars_encoded = dict()\n",
    "\n",
    "for var in categorical_vars:\n",
    "    # if var != 'species':\n",
    "    filtered_data[var] = encoder.fit_transform(filtered_data[var])\n",
    "    dict_vars_encoded[var] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "\n",
    "print(dict_vars_encoded)\n",
    "filtered_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_species = dict_vars_encoded['species']\n",
    "dict_island = dict_vars_encoded['island']\n",
    "dict_sex = dict_vars_encoded['sex']\n",
    "\n",
    "print(dict_species)\n",
    "print(dict_island)\n",
    "print(dict_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divid input & outputÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = filtered_data.drop('species', axis=1), filtered_data['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = \n",
    "model_1 = LogisticRegression()\n",
    "model_2 = SGDRegressor()\n",
    "model_3 = LinearRegression()\n",
    "model_4 = Ridge()\n",
    "model_5 = ElasticNet()\n",
    "model_6 = SVR()\n",
    "model_7 = KNeighborsRegressor(n_neighbors=3)\n",
    "model_8 = DecisionTreeRegressor()\n",
    "model_9 = RandomForestRegressor()\n",
    "model_10 = BaggingRegressor()\n",
    "model_11 = ExtraTreesRegressor()\n",
    "model_12 = AdaBoostRegressor()\n",
    "model_13 = XGBRegressor()\n",
    "model_14 = CatBoostRegressor()\n",
    "model_15 = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.fit(X_train,y_train)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_12.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_13.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_14.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_15.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models:\n",
    "models = [model_1, model_2, model_3, model_4, model_5,\n",
    "          model_6, model_7, model_8, model_9, model_10,\n",
    "          model_11, model_12, model_13, model_14, model_15]\n",
    "models_names = ['LogisticRegression', 'SGDRegressor', 'LinearRegression', 'Ridge', 'ElasticNet', 'SVR', 'KNeighborsRegressor', 'DecisionTreeRegressor', 'RandomForestRegressor', 'BaggingRegressor', 'ExtraTreesRegressor', 'AdaBoostRegressor', 'XGBRegressor', 'CatBoostRegressor', 'LGBMRegressor']\n",
    "\n",
    "# models = [model_1, model_7]\n",
    "# models_names = ['logisticRegression', 'KNeighborsRegressor']\n",
    "\n",
    "\n",
    "# Calculate predictions and squared errors for each model:\n",
    "squared_errors = []\n",
    "for model in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # mse = mean_squared_error(y_test, y_pred)\n",
    "    squared_errors.append(f'{mse * 100:.2f}%')  # Format as percentage\n",
    "\n",
    "# Calculate train and test scores:\n",
    "train_score = [model.score(X_train, y_train) for model in models]\n",
    "test_score = [model.score(X_test, y_test) for model in models]\n",
    "\n",
    "# Difference between training and testing ratio\n",
    "ratio = []\n",
    "for train, test in zip(train_score, test_score):\n",
    "    result = train - test\n",
    "    ratio.append(f'{result * 100:.2f}%')\n",
    "\n",
    "# Measure model state:6\n",
    "rate = []\n",
    "for train, test in zip(train_score, test_score):\n",
    "    if train <= 0.65 and test <= 0.65:\n",
    "        rate.append('bad')\n",
    "    elif train > test * 1.10:\n",
    "        rate.append('overfite')\n",
    "    elif train > 0.65 and train < 0.80 and test > 0.65 and test < 0.80:\n",
    "        rate.append('middle')\n",
    "    elif train >= 0.80 and test >= 0.80 and train < 1.00 and test < 1.00:\n",
    "        rate.append('good')\n",
    "    elif train >= 0.80 and test < 0.80:\n",
    "        rate.append('high train, low test')\n",
    "    else:\n",
    "        rate.append('unknown')\n",
    "\n",
    "# Create DataFrame\n",
    "model_score = pd.DataFrame({\n",
    "    'Model': models_names,\n",
    "    'Train score': [f'{round(score * 100, 2)}%' for score in train_score],\n",
    "    'Test score': [f'{round(score * 100, 2)}%' for score in test_score],\n",
    "    'Ratio difference': ratio,\n",
    "    'Evaluate model': rate,\n",
    "    'Squared error': squared_errors\n",
    "})\n",
    "\n",
    "# Show result:\n",
    "model_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Answer**:\n",
    "\n",
    "Overall, Following models:\n",
    "- KNeighborsRegressor\n",
    "- RandomForestRegressor\n",
    "- ExtraTreesRegressor\n",
    "- catBoostRegressor \n",
    "\n",
    "Show the best performance with high scores and low squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(model_1, './models/LogisticRegression.pkl')\n",
    "joblib.dump(model_7, './models/KNeighborsRegressor.pkl')\n",
    "joblib.dump(model_9, './models/RandomForestRegressor.pkl')\n",
    "joblib.dump(model_11, './models/ExtraTreesRegressor.pkl')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "logistic_regression_model = joblib.load('./models/LogisticRegression.pkl')\n",
    "knn_model = joblib.load('./models/KNeighborsRegressor.pkl')\n",
    "random_forest_model = joblib.load('./models/RandomForestRegressor.pkl')\n",
    "extra_trees_model = joblib.load('./models/ExtraTreesRegressor.pkl')\n",
    "\n",
    "# Create new test data\n",
    "new_data = pd.DataFrame({\n",
    "    'island': ['Biscoe', 'Torgersen', 'Biscoe'],\n",
    "    'culmen_length_mm': [42.1, 39.0, 41.1],\n",
    "    'culmen_depth_mm': [19.1, 21.3, 18.2],\n",
    "    'flipper_length_mm': [195.0, 190.0, 192.0],\n",
    "    'body_mass_g': [3000, 3700, 2500],\n",
    "    'sex': ['MALE', 'FEMALE', 'MALE']\n",
    "})\n",
    "\n",
    "# Encode the categorical variables in the new data\n",
    "for var in categorical_vars:\n",
    "    if var != 'species':\n",
    "        new_data[var] = new_data[var].map(dict_vars_encoded[var])\n",
    "\n",
    "# Scale the new data using the already fitted scaler\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Make predictions with each model\n",
    "logistic_regression_prediction = logistic_regression_model.predict(new_data_scaled)\n",
    "knn_prediction = knn_model.predict(new_data_scaled)\n",
    "random_forest_prediction = random_forest_model.predict(new_data_scaled)\n",
    "extra_trees_prediction = extra_trees_model.predict(new_data_scaled)\n",
    "\n",
    "# Print predictions\n",
    "print(\"LogisticRegression Predictions:\", logistic_regression_prediction)\n",
    "print(\"KNeighborsRegressor Predictions:\", knn_prediction)\n",
    "print(\"RandomForestRegressor Predictions:\", random_forest_prediction)\n",
    "print(\"ExtraTreesRegressor Predictions:\", extra_trees_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random sample from the cleaned data\n",
    "random_sample = filtered_data.sample(n=10, random_state=1)\n",
    "print(\"Random Sample:\")\n",
    "print(random_sample)\n",
    "\n",
    "# Separate the features and target variable\n",
    "random_sample_X = random_sample.drop('species', axis=1)\n",
    "random_sample_y = random_sample['species']\n",
    "\n",
    "\n",
    "random_sample_X\n",
    "\n",
    "# Fill missing values with the mean of the column\n",
    "# random_sample_X = random_sample_X.fillna(random_sample_X.mean())\n",
    "\n",
    "# Scale the random sample using the already fitted scaler\n",
    "random_sample_scaled = scaler.transform(random_sample_X)\n",
    "\n",
    "# Make predictions with each model\n",
    "logistic_regression_prediction = logistic_regression_model.predict(random_sample_scaled)\n",
    "knn_prediction = knn_model.predict(random_sample_scaled)\n",
    "random_forest_prediction = random_forest_model.predict(random_sample_scaled)\n",
    "extra_trees_prediction = extra_trees_model.predict(random_sample_scaled)\n",
    "\n",
    "# Print predictions\n",
    "print(\"LogisticRegression Prediction:\", logistic_regression_prediction)\n",
    "print(\"KNeighborsRegressor Prediction:\", knn_prediction)\n",
    "print(\"RandomForestRegressor Prediction:\", random_forest_prediction)\n",
    "print(\"ExtraTreesRegressor Prediction:\", extra_trees_prediction)\n",
    "\n",
    "# Print the actual species\n",
    "print(\"Actual Species:\", random_sample_y.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
